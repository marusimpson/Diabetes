# Diabetes
# -*- coding: utf-8 -*-
"""Copia de EstudioDiabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RJRZpEffArdQ6ifWIh_NylVTqXWipkDF

Se utiliz√≥ la Pima Indians Diabetes Database (PIDD),
cuya propiedad original pertenece al National Institute of
Diabetes and Digestive and Kidney Diseases, y los datos fueron
obtenidos del UCI Machine Learning Repository - Pima
Indians Diabetes Data Set (2016). Las unidades de an√°lisis
consistieron en 768 mujeres residentes cerca de Phoenix,
Arizona, EEUU, pertenecientes a la etnia Pima y con al menos
21 a√±os de edad.
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Leer el archivo Excel (con extensi√≥n .xlsx)
df = pd.read_csv("diabetes.csv")

# Mostrar las primeras filas
print("Primeras filas del dataset:")
print(df.head())

"""Ver cantidad de filas y columnas"""

df.shape

"""Descripci√≥n de los datos:

1. Embarazos: Cantidad de embarazos  de la paciente

2. Glucosa: Concentraci√≥n de glucosa plasm√°tica a las 2hs de una
prueba de tolerancia oral a la glucosa (G120 mg/dl)

3. Presion Arterial: Presi√≥n arterial diast√≥lica (PAD mmHg.)

4. Espesor de Piel: Grosor del pliegue de la piel del tr√≠ceps (GPPT mm)

5. Insulina: Concentraci√≥n de insulina s√©rica a las 2hs de una prueba
de tolerancia oral a la glucosa (I120 mU/ml)

6. IMC

7. Funci√≥n de Ascendencia Diab√©tica √≥ Funci√≥n pedigr√≠ de la diabetes: Antecedentes Familiares o funci√≥n de pedigr√≠ de diabetes
(FPD)

8. Edad: Tiempo de vida de la persona.

9. Diabetes √≥ Resultado: Esta variable determina si la persona tiene Diabetes o no la tiene.
"""

df

"""Vemos las claves del dataframe. En mi caso edite el archico CSV antes de cargarlo"""

df.keys()

df.columns

"""Comprobamos que no existan datos faltantes"""

df.info()

"""Resumen estadistico"""

df.describe()

"""Estos son algunos puntos que podemos notar sobre los datos:

* Todas nuestras caracter√≠sticas son num√©ricas
* Tenemos un tama√±o de muestra total de 768
* No faltan valores con los que lidiar en este momento
* Algunas caracter√≠sticas tienen un valor m√≠nimo de 0 que es sospechoso para los humanos (vivos):

  - M√≠nima glucosa = 0          (5   casos)
  - Presi√≥n arterial m√≠nima = 0 (35  casos)
  - Espesor de piel m√≠nimo = 0  (227 casos)
  - Min insulina = 0            (374 casos)
  - Min ICM = 0                 (11  casos)

  En grupo se decide si convertimos estos ceros en nulos y los eliminamos (quedarian 392 datos) o ponemos una media
"""

columnas_revisar = ['Glucosa', 'PresionArterial', 'GrosorPiel', 'Insulina', 'IMC']

# Crear un DataFrame con el conteo de ceros por columna
ceros_por_columna = (df[columnas_revisar] == 0).sum()

# Mostrar el resultado
print("Cantidad de ceros por columna:")
print(ceros_por_columna)

"""Hago una cuadricula de histogramas para observasr las variables numericas"""

df.hist(figsize=(12,8))
plt.show()

"""Comprobamos la cantidad de datos faltantes de mi dataset"""

df.isnull().sum()

"""MATRIZ DE CORRELACIONES

Observamos la correlaci√≥n de las variables con la variable DIABETES (ultimna columna).

Es para analizar en grupo
"""

df.corr().Diabetes.sort_values()

import seaborn as sns
correlation_matrix = df.corr(numeric_only=True)
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Matriz de Correlaci√≥n')
plt.show()

from pandas.plotting import scatter_matrix
scatter_matrix(df, figsize=(14,10))

plt.savefig('scatter_diabetes.jpg')
plt.show()

"""A CREAR DATA TRAIN Y TEST!!!

TRAIN: 80% -TEST: 20%

Creamos las variables y separamos

X (predictoras) (¬øPor convenci√≥n x mayuscula?)

y (etiquetas)
"""

X = df.drop('Diabetes', axis=1) #Quitamos la variable respuesta Diabetes
y = df.Diabetes # Variable respuesta

from sklearn.model_selection import train_test_split

"""Dividisi√≥n en entrenamiento y testeo"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Reemplazar los ceros solo despu√©s de dividir, usando la media del conjunto de entrenamiento"""

from sklearn.impute import SimpleImputer

# Columnas donde los ceros deben ser reemplazados
columnas_a_corregir = ['Glucosa', 'PresionArterial', 'GrosorPiel', 'Insulina', 'IMC']
# Crear el imputador: reemplazar√° ceros por la media
imputador = SimpleImputer(missing_values=0, strategy='mean')
# Ajustar el imputador solo con los datos de entrenamiento
X_train[columnas_a_corregir] = imputador.fit_transform(X_train[columnas_a_corregir])
# Aplicar el mismo imputador al conjunto de prueba
X_test[columnas_a_corregir] = imputador.transform(X_test[columnas_a_corregir])

X_train.describe()

"""ENTRENAMIENTO DE VARIOS MODELOS DE CLASIFICACI√ìN"""

from sklearn.linear_model import SGDClassifier # Clasificador lineal Descenso de Gradiente Estoc√°stico (Stochastic Gradient Descent)
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC # M√°quina de vectores de soporte
from sklearn.neighbors import KNeighborsClassifier # Vecinos mas cercanos
from sklearn.linear_model import LogisticRegression # Regresi√≥n Logistica

"""Instanciaci√≥n de las seis clases"""

sgd_clf = SGDClassifier()
tree_clf = DecisionTreeClassifier(max_depth=3, random_state=42)
forest_clf = RandomForestClassifier()
svc_clf = SVC()
knn_clf = KNeighborsClassifier(n_neighbors= 5) # 5 vecinos queremos que utilice
lr_clf = LogisticRegression()

"""Entrenamiento de los modelos"""

sgd_clf.fit(X_train, y_train)
tree_clf.fit(X_train, y_train)
forest_clf.fit(X_train, y_train)
svc_clf.fit(X_train, y_train)
knn_clf.fit(X_train, y_train)
lr_clf.fit(X_train, y_train)

"""Evaluaci√≥n de desempe√±o de los modelos con la matriz de confusi√≥n"""

#from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, confusion_matrix

y_train_prediccion_sgd = cross_val_predict(sgd_clf, X_train, y_train, cv = 5)
y_train_prediccion_tree = cross_val_predict(tree_clf, X_train, y_train, cv = 5)
y_train_prediccion_forest = cross_val_predict(forest_clf, X_train, y_train, cv = 5)
y_train_prediccion_svc = cross_val_predict(svc_clf, X_train, y_train, cv = 5)
y_train_prediccion_knn = cross_val_predict(knn_clf, X_train, y_train, cv = 5)
y_train_prediccion_lr = cross_val_predict(lr_clf, X_train, y_train, cv = 5)

"""Descenso de Gradiente Estoc√°stico"""

print(confusion_matrix(y_train, y_train_prediccion_sgd))
print(f'Sensibilidad: {recall_score(y_train, y_train_prediccion_sgd)}')
print(f'Accuracy: {accuracy_score(y_train, y_train_prediccion_sgd)}')
print(f'Precision: {precision_score(y_train, y_train_prediccion_sgd)}')
print(f'F1 Score: {f1_score(y_train, y_train_prediccion_sgd)}')

"""√ÅRBOL DE DECISI√ìN"""

print(confusion_matrix(y_train, y_train_prediccion_tree))
print(f'Sensibilidad: {recall_score(y_train, y_train_prediccion_tree)}')
print(f'Accuracy: {accuracy_score(y_train, y_train_prediccion_tree)}')
print(f'Precision: {precision_score(y_train, y_train_prediccion_tree)}')
print(f'F1 Score: {f1_score(y_train, y_train_prediccion_tree)}')

"""RANDOM FOREST"""

print(confusion_matrix(y_train, y_train_prediccion_forest))
print(f'Sensibilidad: {recall_score(y_train, y_train_prediccion_forest)}')
print(f'Accuracy: {accuracy_score(y_train, y_train_prediccion_forest)}')
print(f'Precision: {precision_score(y_train, y_train_prediccion_forest)}')
print(f'F1 Score: {f1_score(y_train, y_train_prediccion_forest)}')

"""M√°quina de vectores de soporte"""

print(confusion_matrix(y_train, y_train_prediccion_svc))
print(f'Sensibilidad: {recall_score(y_train, y_train_prediccion_svc)}')
print(f'Accuracy: {accuracy_score(y_train, y_train_prediccion_svc)}')
print(f'Precision: {precision_score(y_train, y_train_prediccion_svc)}')
print(f'F1 Score: {f1_score(y_train, y_train_prediccion_svc)}')

"""KNN (Vecinos mas cercanos)"""

print(confusion_matrix(y_train, y_train_prediccion_knn))
print(f'Sensibilidad: {recall_score(y_train, y_train_prediccion_knn)}')
print(f'Accuracy: {accuracy_score(y_train, y_train_prediccion_knn)}')
print(f'Precision: {precision_score(y_train, y_train_prediccion_knn)}')
print(f'F1 Score: {f1_score(y_train, y_train_prediccion_knn)}')

"""REGRESI√ìN LOGISTICA"""

print(confusion_matrix(y_train, y_train_prediccion_lr))
print(f'Sensibilidad: {recall_score(y_train, y_train_prediccion_lr)}')
print(f'Accuracy: {accuracy_score(y_train, y_train_prediccion_lr)}')
print(f'Precision: {precision_score(y_train, y_train_prediccion_lr)}')
print(f'F1 Score: {f1_score(y_train, y_train_prediccion_lr)}')

"""Graficamos el arbol de decision:
*   GINI: medida de impureza (falta de homogeneidad). Cuanto mayor sea el valor del √çndice de Gini, mayor ser√° la probabilidad de que se produzcan clasificaciones err√≥neas.
*   SAMPLES: n√∫mero de observaciones o ejemplos (filas de datos) que llegan a un nodo espec√≠fico del √°rbol durante el entrenamiento.
*   VALUE: es una lista (o vector) que muestra el n√∫mero de muestras de cada clase presentes en ese nodo.
"""

from sklearn.tree import plot_tree
# Paso 7: Visualizar el √°rbol
plt.figure(figsize=(20,10))
plot_tree(tree_clf, feature_names=X.columns, class_names=["No Diabetes", "Diabetes"], filled=True, proportion=True)
plt.title("√Årbol de decisi√≥n para detecci√≥n de diabetes")
plt.show()

"""Graficamos RANDOM FOREST"""

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

# Seleccionar uno de los √°rboles (por ejemplo, el primero)
tree = forest_clf.estimators_[0]

# Graficar el √°rbol
plt.figure(figsize=(20,10))
plot_tree(tree, feature_names=X.columns, class_names=["No Diabetes", "Diabetes"], filled=True, rounded=True)
plt.title("Un √°rbol dentro del Random Forest")
plt.show()

import joblib

# Guardar el modelo en un archivo
joblib.dump(tree_clf, 'modelo_arbol_decision.pkl')

# Descargar el archivo a tu computadora
from google.colab import files
files.download('modelo_arbol_decision.pkl')

"""ARMAMOS LA WEB"""

!pip install streamlit pyngrok scikit-learn joblib --quiet

from google.colab import files
uploaded = files.upload()

import streamlit as st
import joblib
import numpy as np
from datetime import datetime

# Cargar modelo
modelo = joblib.load('modelo_arbol_decision.pkl')

# ================== ESTILOS B√ÅSICOS ==================
st.markdown("""
    <style>
        body, .main {
            background-color: #ffffff;
            color: #000000;
            font-family: sans-serif;
        }
        .top-bar {
            background: #005b96;
            color: white;
            padding: 1rem 2rem;
            font-weight: bold;
            font-size: 1.5rem;
            margin-bottom: 1rem;
        }
        .resultado {
            padding: 1.5rem;
            border-radius: 10px;
            font-size: 1.2rem;
            margin-top: 2rem;
            text-align: center;
        }
        .alto {
            background-color: #ffe5e5;
            border: 2px solid #c5221f;
            color: #c5221f;
        }
        .bajo {
            background-color: #e0fff2;
            border: 2px solid #008a5e;
            color: #008a5e;
        }
    </style>
""", unsafe_allow_html=True)

# ================== ENCABEZADO ==================
st.markdown('<div class="top-bar">DiabetesScan Pro</div>', unsafe_allow_html=True)

# ================== FORMULARIO ==================
with st.form("formulario"):
    st.subheader("üìã Ingresar datos del paciente")

    col1, col2 = st.columns(2)

    with col1:
        embarazos = st.number_input("N¬∞ de embarazos", min_value=0, step=1)
        edad = st.number_input("Edad", min_value=21, step=1)
        pedigree = st.number_input("Historial Familiar (funci√≥n de pedigr√≠)", min_value=0.0, step=0.01)

    with col2:
        glucosa = st.number_input("Glucosa (mg/dL)", min_value=0.0, step=1.0)
        presion = st.number_input("Presi√≥n Arterial (mmHg)", min_value=0.0, step=1.0)
        piel = st.number_input("Pliegue cut√°neo (mm)", min_value=0.0, step=1.0)
        insulina = st.number_input("Insulina (ŒºU/mL)", min_value=0.0, step=1.0)
        imc = st.number_input("IMC (kg/m¬≤)", min_value=0.0, step=0.1)

    analizar = st.form_submit_button("Analizar Riesgo")

# ================== PREDICCI√ìN ==================
if analizar:
    entrada = np.array([[embarazos, glucosa, presion, piel, insulina, imc, pedigree, edad]])
    prediccion = modelo.predict(entrada)[0]

    if prediccion == 1:
        st.markdown('<div class="resultado alto"><strong>üî¥ Alto riesgo de diabetes</strong></div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="resultado bajo"><strong>üü¢ Bajo riesgo de diabetes</strong></div>', unsafe_allow_html=True)

!nohup streamlit run app.py &>/dev/null &

from pyngrok import ngrok

# Si ya pusiste tu token anteriormente, omite esta l√≠nea
ngrok.set_auth_token("2xygsROLh7qNKOm07pUfAvU8Tyy_6MrKmf2HwUU2KpsBBojGG")

# Matar t√∫neles anteriores y crear uno nuevo
ngrok.kill()
public_url = ngrok.connect(8501)
print("‚úÖ Tu app est√° disponible en:", public_url)
